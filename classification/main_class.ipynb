{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a94655-ed00-4646-a5ad-37d664f54f3f",
   "metadata": {
    "id": "97a94655-ed00-4646-a5ad-37d664f54f3f",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " # __Classification of  COVID-19 on CT scans using Deep Learning__\n",
    "\n",
    "## __ResNet50, ResNet50r, DenseNet121, MobileNet_v3_large and CaiT_xxs_24_224__\n",
    "\n",
    "\n",
    "Image classification of CT scans in one of three classes: CAP, Covid, NonCovid\n",
    "\n",
    "\n",
    "Datasets sourced from: \n",
    "* https://www.kaggle.com/maedemaftouni/large-covid19-ct-slice-dataset - Curated COVID-19 CT scan dataset from 7 public datasets\n",
    "* https://data.mendeley.com/datasets/3y55vgckg6/2 - COVID-19 and common pneumonia chest CT dataset (only common pneumonia cases used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d1e60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "e78d1e60"
   },
   "source": [
    "<h2>Table of Contents</h2>\n",
    "    <ul>\n",
    "    <li><a href=\"#Section_1\">Import libraries and supporting functions </a></li>\n",
    "    <li><a href=\"#Section_2\"> Exploring the dataset </a></li>\n",
    "    <li><a href=\"#Section_3\"> Build the experimental setup </a></li>\n",
    "    <li><a href=\"#Section_4\"> Training </a></li>\n",
    "    <li><a href=\"#Section_5\"> Evaluation on test dataset </a></li>\n",
    "    <li><a href=\"#Section_6\"> Image inference on test dataset </a></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "df852072",
   "metadata": {
    "id": "df852072",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "__Verify the GPU's available and their capacity__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3ec83da0",
   "metadata": {
    "id": "3ec83da0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Install required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## __Importing Libraries supporting functions and methods__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0o2qLBkmqGAx",
   "metadata": {
    "id": "0o2qLBkmqGAx",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658226007668,
     "user_tz": -60,
     "elapsed": 3756,
     "user": {
      "displayName": "Aze Gln",
      "userId": "12590864696663313384"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Library required to run transformer Class-Attention in Image Transformers (CaiT)\n",
    "%%capture\n",
    "!pip install timm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mE7JgjB8sad3",
   "metadata": {
    "id": "mE7JgjB8sad3",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658226010636,
     "user_tz": -60,
     "elapsed": 2973,
     "user": {
      "displayName": "Aze Gln",
      "userId": "12590864696663313384"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Use to compute AUROC\n",
    "%%capture\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6745b42e-d608-4597-ac38-81dd2efbb985",
   "metadata": {
    "id": "6745b42e-d608-4597-ac38-81dd2efbb985",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658226011670,
     "user_tz": -60,
     "elapsed": 1037,
     "user": {
      "displayName": "Aze Gln",
      "userId": "12590864696663313384"
     }
    },
    "outputId": "acd61318-7a18-4476-bde2-2ad03d522497"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using PyTorch version 1.12.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import date\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "torch.manual_seed(123)\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hCpUEovpbvhD",
   "metadata": {
    "id": "hCpUEovpbvhD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### __Change directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "U7sDn8Ec94Qw",
   "metadata": {
    "id": "U7sDn8Ec94Qw",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658226015024,
     "user_tz": -60,
     "elapsed": 2,
     "user": {
      "displayName": "Aze Gln",
      "userId": "12590864696663313384"
     }
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/MyDrive/INM363_classification/classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ZndOH3yw9p4A",
   "metadata": {
    "id": "ZndOH3yw9p4A",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658226042657,
     "user_tz": -60,
     "elapsed": 1082,
     "user": {
      "displayName": "Aze Gln",
      "userId": "12590864696663313384"
     }
    }
   },
   "outputs": [],
   "source": [
    "from covid_class_dataset import CovidDataset, split_dataset, get_transform, get_vt_transform\n",
    "from train_class import get_classification_model, main\n",
    "from plotting import training_stats, show_predictions, show_misses\n",
    "from evaluation_metrics import predictions, Metrics, misclassification, train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c427a941-8b23-4e8e-9362-4e08d9d0947f",
   "metadata": {
    "id": "c427a941-8b23-4e8e-9362-4e08d9d0947f",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658226044735,
     "user_tz": -60,
     "elapsed": 2,
     "user": {
      "displayName": "Aze Gln",
      "userId": "12590864696663313384"
     }
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82f8fc-f229-4860-a7a2-27065036d246",
   "metadata": {
    "id": "6d82f8fc-f229-4860-a7a2-27065036d246",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## __Exploring the dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bWD8Ol7ahC09",
   "metadata": {
    "id": "bWD8Ol7ahC09",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The dataset has three classes:\n",
    "\n",
    "* COVID - Corona Virus Disease\n",
    "* CAP - Community-Acquired Pneumonia \n",
    "* Non-covid - Healthy Lungs"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Decompress the dataset file\n",
    "!unzip curated_data.zip"
   ],
   "metadata": {
    "id": "U09uPFNoACfS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "U09uPFNoACfS",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f56504-3c77-4fa5-8636-2886093a2770",
   "metadata": {
    "id": "71f56504-3c77-4fa5-8636-2886093a2770",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Directory to access the images\n",
    "data_dir = os.path.join(os.getcwd(), 'curated_data')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9f730-5c15-44d9-bb31-02b2f447044f",
   "metadata": {
    "id": "eaa9f730-5c15-44d9-bb31-02b2f447044f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['cap', 'covid','non_covid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add0d09-af21-4f44-8c0f-3eef0cd76e54",
   "metadata": {
    "id": "3add0d09-af21-4f44-8c0f-3eef0cd76e54",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data =[]\n",
    "data_id = {}\n",
    "paths = {}\n",
    "for idx, name, in enumerate (class_names):\n",
    "    path = os.path.join(data_dir, name)\n",
    "    l_dir = sorted(os.listdir(path))\n",
    "    data_id[name] = l_dir\n",
    "    paths[name] = path\n",
    "    for file in l_dir:\n",
    "        file_path = os.path.join(path, file)\n",
    "        data.append([name, file_path, file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5456731",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "c5456731"
   },
   "outputs": [],
   "source": [
    "# Collates the paths and classes of each image in a dataframe for further processing\n",
    "data_table = pd.DataFrame(data, columns=['image_label', 'image_path', 'image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed17ff-f2d1-45a6-b4b0-0b81f2cbd225",
   "metadata": {
    "id": "88ed17ff-f2d1-45a6-b4b0-0b81f2cbd225",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k,v in data_id.items():\n",
    "    print(f'Directory {k}, contains {len(data_id[k])}, instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2c187-10a0-47a5-b28d-339f115f06ea",
   "metadata": {
    "id": "22c2c187-10a0-47a5-b28d-339f115f06ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_table.image_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120d137-f396-4e7c-a4e4-8356b6a03d90",
   "metadata": {
    "id": "7120d137-f396-4e7c-a4e4-8356b6a03d90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f398b90-a654-40e8-b0bf-eebc17b43710",
   "metadata": {
    "id": "1f398b90-a654-40e8-b0bf-eebc17b43710",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### __Classes distribution__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f5713",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "883f5713"
   },
   "source": [
    "Here we will build a histogram to visualise the number of images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52c9a8-f572-4b7a-a1cc-c957b91fbcc7",
   "metadata": {
    "id": "cf52c9a8-f572-4b7a-a1cc-c957b91fbcc7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "dist = data_table.image_label.value_counts().plot.bar(color= \"Green\", alpha= 1)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"Counts\", fontsize=14)\n",
    "plt.xlabel(\"Class\")\n",
    "plotname = 'class_dist.eps'\n",
    "plt.savefig(os.path.join(os.getcwd(), plotname), bbox_inches='tight',\n",
    "            format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382f7f2-51e0-4430-9954-ee11e8778f68",
   "metadata": {
    "id": "6382f7f2-51e0-4430-9954-ee11e8778f68",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can address the class imbalance by \n",
    "* splitting the dataset by stratifiying the images by the image_label\n",
    "* using weighted cross entropy\n",
    "* evaluating the performance of models with metrics that penalise misclassification of the minority class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f304e-1ab6-4088-b354-5528ebed273a",
   "metadata": {
    "id": "9a3f304e-1ab6-4088-b354-5528ebed273a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### __Visualising raw images__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af9cfd-fca9-4fa0-abc3-e64c5e02ef1a",
   "metadata": {
    "id": "24af9cfd-fca9-4fa0-abc3-e64c5e02ef1a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we will visualise the CT scan slices before applying augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T9bSRebyNhLA",
   "metadata": {
    "id": "T9bSRebyNhLA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', font_scale=1.2)\n",
    "np.random.seed(123)\n",
    "c = 1\n",
    "eps = False\n",
    "caps_id =[]\n",
    "covid_id =[]\n",
    "non_covid_id = []\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "for i in range(9):\n",
    "    if i < 3:\n",
    "        idx = np.random.choice(data_table[data_table['image_label'] == 'cap'].index.values)\n",
    "        file = data_table.iloc[idx]['image_path'] \n",
    "        # color = 'blue'\n",
    "        caps_id.append(data_table.iloc[idx]['image_id'].strip('.png' or '.jpg'))\n",
    "\n",
    "    elif 6 > i >2:\n",
    "        idx = np.random.choice(data_table[data_table['image_label'] == 'covid'].index.values)\n",
    "        file = data_table.iloc[idx]['image_path']\n",
    "        # color = 'red'\n",
    "        covid_id.append(data_table.iloc[idx]['image_id'].strip('.png'))\n",
    "\n",
    "    else:\n",
    "        idx = np.random.choice(data_table[data_table['image_label'] == 'non_covid'].index.values)\n",
    "        file = data_table.iloc[idx]['image_path']\n",
    "        # color = 'green'\n",
    "        non_covid_id.append(data_table.iloc[idx]['image_id'].strip('.png'))\n",
    "\n",
    "    img = Image.open(file)\n",
    "    img_= img.resize((256,256))\n",
    "\n",
    "    ax = fig.add_subplot(1, 9, c)\n",
    "    c+=1\n",
    "    ax.imshow(img_, cmap = 'gray')\n",
    "\n",
    "    ax.set_title(data_table.iloc[idx].image_label, fontsize = 14, color = 'navy')\n",
    "    ax.axes.xaxis.set_ticks([])\n",
    "    ax.axes.yaxis.set_ticks([])\n",
    "\n",
    "print('CAPs ids', caps_id)\n",
    "print('COVID ids', covid_id)\n",
    "print('COVID ids', non_covid_id)\n",
    "\n",
    "\n",
    "# Save image in eps format\n",
    "if eps: \n",
    "    plotname = 'class3.eps'\n",
    "    plt.savefig(os.path.join(os.getcwd(), plotname), bbox_inches='tight',\n",
    "                format='eps', dpi=300)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c94dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "354c94dc"
   },
   "source": [
    "## __Build the experimental setup__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888988f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "e888988f"
   },
   "source": [
    "To buil the setup we will use five Deep Learning (DL) neural networks::\n",
    "\n",
    "* ResNet-50\n",
    "* ResNet-50r\n",
    "* DenseNet-121\n",
    "* MobileNet-v3-large\n",
    "* CaiT\n",
    "\n",
    "We will train the neural network to optimize the loss functions (objective):\n",
    "\n",
    "* Cross entropy\n",
    "* Weighted cross entropy (added penalisation for the class imbalance)\n",
    "\n",
    "Finally, we will optimize the objective function by using the optimizer\n",
    "* Adam\n",
    "* AdamW\n",
    "\n",
    "In total, we will have 20 experiments as a result of each of the combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3b7aa",
   "metadata": {
    "id": "35e3b7aa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exps =[i for i in range(1, 21)]\n",
    "exp_models = sorted(['resnet50', 'resnet50r', 'densenet121', 'mobilenet_v3_l', 'cait_24_224'] * 4)\n",
    "exp_optim = ['Adam', 'AdamW'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cea93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "212cea93"
   },
   "outputs": [],
   "source": [
    "exp_loss=[]\n",
    "for i in range (1,21,4):\n",
    "    if i and i+1 in exps:\n",
    "        exp_loss.extend(['CE']*2)\n",
    "    if i+2 and i+3 in exps:\n",
    "        exp_loss.extend(['wCE']*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5e183",
   "metadata": {
    "id": "a7a5e183",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "setup = pd.DataFrame({'Exp':exps,'Net': exp_models, 'Loss': exp_loss, 'Optim':exp_optim })"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### __Experimental setup__\n",
    "\n",
    "\n",
    "Experiment\t |Architecture  | Loss\t | Optimzer\n",
    "-----|--------------|--------|--------\n",
    "1\t |CaiT          |   CE   | Adam\n",
    "2\t |CaiT          |\tCE\t | AdamW\n",
    "3\t |CaiT          |   wCE\t | Adam\n",
    "4\t |CaiT          |   wCE\t | AdamW\n",
    "5\t |DenseNet-121  |\tCE\t | Adam\n",
    "6\t |DenseNet-121  |   CE\t | AdamW\n",
    "7\t |DenseNet-121  |   wCE\t | Adam\n",
    "8\t |DenseNet-121\t|   wCE\t | AdamW\n",
    "9\t |MobileNet-v3-l|\tCE\t | Adam\n",
    "10\t |MobileNet-v3-l|   CE\t | AdamW\n",
    "11\t |MobileNet-v3-l|   wCE\t | Adam\n",
    "12\t |MobileNet-v3-l|   wCE\t | AdamW\n",
    "13\t |ResNet-50\t    |   CE\t | Adam\n",
    "14\t |ResNet-50\t    |   CE\t | AdamW\n",
    "15\t |ResNet-50\t    |   wCE\t | Adam\n",
    "16\t |ResNet-50\t    |   wCE\t | AdamW\n",
    "17\t |ResNet-50r\t|   CE\t | Adam\n",
    "18\t |ResNet-50r\t|   CE\t | AdamW\n",
    "19\t |ResNet-50r\t|   wCE\t | Adam\n",
    "20\t |ResNet-50r\t|   wCE\t | AdamW"
   ],
   "metadata": {
    "id": "Hr87mXSvIdpl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "Hr87mXSvIdpl"
  },
  {
   "cell_type": "markdown",
   "id": "d2ecd274-c304-4852-acdb-7a4919ce678b",
   "metadata": {
    "id": "d2ecd274-c304-4852-acdb-7a4919ce678b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## __Training__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aaf7f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "e4aaf7f7"
   },
   "source": [
    "Here we will bild our dataset using the class constructor to convert the images and labels into tensors. The tensors will be passed to the dataloader which will batchify the data for the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0657a-870a-420e-ad39-6d4e8c24fb8c",
   "metadata": {
    "id": "20d0657a-870a-420e-ad39-6d4e8c24fb8c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    today = date.today()\n",
    "    date2 = today.strftime('%B %d, %Y')\n",
    "\n",
    "    # Split dataset\n",
    "\n",
    "    train, val, test = split_dataset(data_table, label_col ='image_label', seed=123)\n",
    "\n",
    "    print('Train images:', len(train))\n",
    "    print('Validation images:',len(val))\n",
    "    print('Test images: ', len(test))\n",
    "\n",
    "    # Define experiment to train and the number of run\n",
    "\n",
    "    exp = 17\n",
    "    run = '10'\n",
    "\n",
    "    # Extract the architecture, optimizer and loss from the setup table using index for exp \n",
    "\n",
    "    idx = setup.Exp[setup.Exp == exp].index[0]\n",
    "    model = setup.iloc[idx]['Net']\n",
    "    optim = setup.Optim.iloc[idx]\n",
    "    loss = setup.Loss.iloc[idx]\n",
    "\n",
    "    # Creating weights to input onto the wCE\n",
    "    class_count ={}\n",
    "    for i, lb in enumerate (sorted(np.unique(train.image_label))):\n",
    "        class_count[i] = train.image_label.value_counts()[lb]\n",
    "\n",
    "    torch.set_printoptions(precision=5)\n",
    "    weights = 1/torch.tensor(list(class_count.values()))\n",
    "    weights.to(device) \n",
    "\n",
    "    # Create the output directory\n",
    "\n",
    "    output_dir = os.path.join(model, 'exp_'+ str(exp), run)\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=False)\n",
    "        print('Directory successfully created')\n",
    "    except OSError as error:\n",
    "        print('Directory already exist')\n",
    "        \n",
    "    #Create data class to conver the images into tensors to feed on to the dataloaders\n",
    "        \n",
    "    if model!= 'cait_24_224':\n",
    "        train_dataset = CovidDataset(train, 'image_path', 'image_label',\n",
    "                                     get_transform(train=True))\n",
    "        val_dataset = CovidDataset(val, 'image_path', 'image_label', \n",
    "                                   get_transform(train=False))\n",
    "        test_dataset = CovidDataset(test, 'image_path', 'image_label', \n",
    "                                    get_transform(train=False))\n",
    "\n",
    "    else:\n",
    "        train_dataset = CovidDataset(train, 'image_path', 'image_label',\n",
    "                                    get_vt_transform(train=True))\n",
    "        val_dataset = CovidDataset(val, 'image_path', 'image_label',\n",
    "                                  get_vt_transform(train =False))\n",
    "        test_dataset = CovidDataset(test, 'image_path', 'image_label',\n",
    "                                    get_vt_transform(train=False))\n",
    "\n",
    "    # training hyperparameters dictionary\n",
    "    \n",
    "    params = {'exp': exp, 'model': model, 'num_classes': 3, 'device': device,\n",
    "          'train_dataset': train_dataset, 'val_dataset': val_dataset, 'batch_size': 8,\n",
    "          'workers': 2, 'loss': loss, 'weights': weights, 'optimizer': optim, 'lr': 2e-5,\n",
    "          'momentum': 0.9, 'weight_decay': 1e-4, 'epochs': 8, 'output_dir': output_dir}\n",
    "    \n",
    "    # Provides information about the model to train and time and date\n",
    "\n",
    "    print(\"Today's date:\", date2)\n",
    "    t = time.localtime()\n",
    "    current_time = time.strftime('%H:%M:%S', t)\n",
    "    print('Current_time', current_time)\n",
    "    print('Model:', model, '|', 'run:', run, '|', 'loss:', loss, '|', 'optimizer:', optim)\n",
    "    \n",
    "    stats_log = main(**params)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0849734",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "c0849734"
   },
   "source": [
    "### __Visualizing the training and validation accuracy and loss__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1200c02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "f1200c02"
   },
   "source": [
    "We can visualize the training and validation accuray loss directly from the stats log or stats from the \n",
    "checkpoint\n",
    "\n",
    "* training_stats(params['model'], hideplot=False, **stats_log)\n",
    "\n",
    "\n",
    "* fig_res = training_stats(checkpoint['stats'], params['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jgiEvfggrQwY",
   "metadata": {
    "id": "jgiEvfggrQwY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w_name = 'model_final_' + str(params['epochs']) + '.pth'\n",
    "checkpoint = torch.load(os.path.join(output_dir, w_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71266d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "a71266d2"
   },
   "source": [
    "We will visualize the stats from  the stats log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc6f88",
   "metadata": {
    "id": "27bc6f88",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_stats(params['model'], hideplot=False, **stats_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e071e15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "5e071e15"
   },
   "source": [
    "## __Evaluating on the test dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879fe9b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "9879fe9b"
   },
   "source": [
    "First we will extract the validation and training accuracies, the maximum validation and training accuracy ad the number of epochs at which the maximum was reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4112c73",
   "metadata": {
    "id": "a4112c73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_stats = checkpoint['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bIxcwCW3bjPN",
   "metadata": {
    "id": "bIxcwCW3bjPN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tr_acc, val_acc, max_acc, max_index, val_loss, min_loss, loss_idx = train_metrics(**train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa004f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "d9aa004f"
   },
   "source": [
    "To evaluate on te test set we require:\n",
    "\n",
    "* Build the test loader \n",
    "* Build the model\n",
    "* Upload the weigths obtained during training onto the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d07a4-48fd-459b-8169-75e0c2fc4c64",
   "metadata": {
    "id": "442d07a4-48fd-459b-8169-75e0c2fc4c64",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size= params['batch_size'], shuffle=True)\n",
    "model_ = get_classification_model(params['model'], params['num_classes'], pretrained=False)\n",
    "model_.load_state_dict(checkpoint['model'], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23406bd5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "23406bd5"
   },
   "source": [
    "### __Obtain the prediction and probabilities__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1eedf8-6a59-4a8d-a748-9baa370fb120",
   "metadata": {
    "id": "6f1eedf8-6a59-4a8d-a748-9baa370fb120",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test, y_pred, y_prob, y_prob_tensor = predictions(model_.to(device), test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a3f95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "8f8a3f95"
   },
   "source": [
    "### Evaluate the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8210af43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "8210af43"
   },
   "source": [
    "We will evaluate the performance of the experiments with the following metrics:\n",
    "\n",
    "* Accuracy\n",
    "* AUROC\n",
    "* Balanced accuracy\n",
    "* F1 \n",
    "* F2 \n",
    "* MCC\n",
    "* Precision\n",
    "* Sensitivity\n",
    "* Specificity \n",
    "\n",
    "We also visualise the TP, TN, FP and FN in the confussion matrix and  a summary of the metrics in  the Classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf674ab-2b44-4f33-b1b3-c9d1cc6194a0",
   "metadata": {
    "id": "dbf674ab-2b44-4f33-b1b3-c9d1cc6194a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics = Metrics(y_test, y_pred, y_prob_tensor, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb58848-e37c-4996-a949-f493e8620130",
   "metadata": {
    "id": "edb58848-e37c-4996-a949-f493e8620130",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.cmatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3868fb5-b820-44d3-808c-69125471c3c3",
   "metadata": {
    "id": "d3868fb5-b820-44d3-808c-69125471c3c3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Model:', params['model'],'|', 'run:', run, '|', 'loss:',params['loss'],'|', 'Optimizer:',\n",
    "params['optimizer'])\n",
    "print('Classification report', metrics.classification_rep(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e435a",
   "metadata": {
    "id": "456e435a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "macro_prec, recall, f1, f2, f1_class, f2_class = metrics.macro_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9142d-aed5-4377-b425-f1379def6bb3",
   "metadata": {
    "id": "e2d9142d-aed5-4377-b425-f1379def6bb3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "micro_prec, micro_rec, micro_f1 = metrics.micro_average()\n",
    "sens, spec, (tp, tn, fp, fn) = metrics.sensitivity_specificity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vvEppnBabvhO",
   "metadata": {
    "id": "vvEppnBabvhO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics_ = [['Date', date.today()], ['Exp', params['exp']], ['Run', run],\n",
    "            ['Architecture', params['model']], ['Loss', params['loss']],\n",
    "            ['Optimizer', params['optimizer']], ['Accuracy', micro_f1],\n",
    "            ['BA', metrics.balanced_acc()],\n",
    "            ['MCC' , metrics.mcc()],\n",
    "            ['F1 macro', f1],\n",
    "            ['Sensitivity', recall],\n",
    "            ['Precision', macro_prec],\n",
    "            ['Specificity', round(np.mean(spec),4)],\n",
    "            ['F2', f2], ['AUROC', metrics.auroc()],\n",
    "            ['F1 per class', f1_class],\n",
    "            ['F2 per class', f2_class],\n",
    "            ['Sensitivity per class', sens], ['Specificity per class', spec],\n",
    "            ['Misses', fp + fn], ['FN', fn], ['FP', fp],\n",
    "            ['tr_acc', tr_acc], ['val_acc', val_acc], \n",
    "            ['Max acc', max_acc], ['Max epoch', max_index+1],\n",
    "            ['val_loss', val_loss], ['best loss', float(min_loss)],\n",
    "            ['loss_idx', loss_idx +1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4aa44",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "9db4aa44"
   },
   "source": [
    "Create a dataframe and save the results in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zZIt0eOPbvhP",
   "metadata": {
    "id": "zZIt0eOPbvhP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics_, columns= ['Metric','Value'],\n",
    "                          index = [i for i in range(len(metrics_))])\n",
    "print(\"Today's date:\", today.strftime('%B %d, %Y'))\n",
    "print('Model:', model,'|', 'run:', run, '|', 'loss:',loss,'|', 'Optimizer:',\n",
    "          params['optimizer'])\n",
    "print('Additional metrics')\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e33fa",
   "metadata": {
    "id": "c27e33fa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_f = 'exp_'+  str(exp)+'_run_'+ run +'.csv'\n",
    "outdir = params['output_dir']\n",
    "df_metrics.to_csv(os.path.join(outdir, save_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d2d55-53ec-46d2-a948-bf9e7801eb2e",
   "metadata": {
    "id": "0a0d2d55-53ec-46d2-a948-bf9e7801eb2e",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  __Inference - Showing prediction on test dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maX_e9kY2lze",
   "metadata": {
    "id": "maX_e9kY2lze",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b122fc7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "4b122fc7"
   },
   "source": [
    "### __Show predictions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MfuFvrOsBSAt",
   "metadata": {
    "id": "MfuFvrOsBSAt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "show_predictions(model_, test_loader, class_names, device= torch.device('cpu'), cait = False,\n",
    "                 outdir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a458f64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "7a458f64"
   },
   "source": [
    "### __Show misclassifications__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XG4R2fKRJ_E_",
   "metadata": {
    "id": "XG4R2fKRJ_E_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "misses_data = misclassification(y_test, y_pred, y_prob, test) \n",
    "\n",
    "# Save the paths to the misclassified images in a csv file\n",
    "misses_data.to_csv(output_dir + '/misses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F9R4Mg4KqAss",
   "metadata": {
    "id": "F9R4Mg4KqAss",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paths = show_misses(misses_data, class_names, 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pClhYs58iav4",
   "metadata": {
    "id": "pClhYs58iav4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create alist of the incorrect ids for visualisation\n",
    "incorrect_ids = []\n",
    "for path in misses_data['image_path']:\n",
    "    im_id = path.replace('/content/drive/MyDrive/INM373_classification/curated_data/', '')\n",
    "    incorrect_ids.append(im_id)\n",
    "incorrect_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UF3zar7bEF9e",
   "metadata": {
    "id": "UF3zar7bEF9e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transpose  the evaluation results and saved them into csv file\n",
    "dft= df_metrics.T\n",
    "df = dft.rename(columns=dft.iloc[0])\n",
    "fname = '/dftranspose.csv'\n",
    "outdir = params['output_dir']\n",
    "df.to_csv(outdir + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W4tjrpF8vcBp",
   "metadata": {
    "id": "W4tjrpF8vcBp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the cache\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "main_class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
